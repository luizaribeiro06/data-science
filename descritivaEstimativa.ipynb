{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm2z98zbKZWTeOs5VrlTps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizaribeiro06/data-science/blob/main/descritivaEstimativa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a70_Lsboa_Yq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats #busca infos em outras bibliotecas tipo o pandas, e essa parte é focada em estatística\n",
        "import pandas as pd\n",
        "\n",
        "#dados de exemplo - criação de um conjunto de números (nesse caso)\n",
        "dados = [10, 20, 30, 40, 50, 100, 150, 200, 300, 500]\n",
        "\n",
        "#média (mean)\n",
        "media = np.mean(dados) #busca na biblioteca\n",
        "\n",
        "#média ponderada (weighted mean)\n",
        "pesos = [1, 1, 1, 1, 1, 2, 2, 2, 3, 3] #de forma respectiva, da os pesos para as notas\n",
        "media_ponderada = np.average(dados, weights=pesos)\n",
        "\n",
        "#mediana (median)\n",
        "mediana = np.median(dados)\n",
        "\n",
        "#mediana ponderada (weighted median)\n",
        "#esses pesos não são os mesmos de cima, logo, é outro cenário (por isso ele ta ignorando os pesos, ta sendo a soma acumulada agora)\n",
        "#1. recebe o argumento dataframe (dados, peso)\n",
        "def mediana_ponderada(dados, pesos):\n",
        "  #2. ordena o df do menor para o maior\n",
        "  dados_ordenados, pesos_ordenados = zip(*sorted(zip(dados, pesos))) #zip:reduz/junta\n",
        "  #3. soma acumulada\n",
        "  soma_pesos = np.cumsum(pesos_ordenados) #função de soma acumulada\n",
        "  #4. divide por 2\n",
        "  return dados_ordenados[np.searchsorted(soma_pesos, soma_pesos[-1] / 2)]\n",
        "\n",
        "mediana_ponderada_valor = mediana_ponderada(dados, pesos)\n",
        "\n",
        "#média aparada (trimmed mean) - remove os 10% menores e maiores valores\n",
        "#vai selecionar um número menor para fazer sentido, irá excluir os extremos e focar no centro\n",
        "media_aparada = stats.trim_mean(dados, proportiontocut=0.1) #o 0.1 é o valor dos 10%, pode ser mudado\n",
        "\n",
        "#IQR (Interquartile Range) - Intervalo interquartil\n",
        "#percentil dentro do desvio padrão\n",
        "\n",
        "#o histograma é cortado pela metade no número da mediana, sendo divido em 3 partes DO DESENHO, sendo que os dois do meio se juntam\n",
        "#em q numero começa o quartil 2 e em q numero ele termina, assim achando o desvio padrão inferior e superior\n",
        "#esses nomes foram dados pois o 2 quartil começa em \"25% e termina em 75%\"\n",
        "p25, p75 = np.percentile(dados, [25, 75])\n",
        "iqr = p75 - p25 #acha o range (a diferença entre o final e o início)\n",
        "\n",
        "#detecção de outliers com iqr\n",
        "#1.5 * range: tendo em vista a divisão em 4 partes, ele vai pegar as outras 3 partes de 0.5 para fazer vezes (tanto no inferior quanto no superior)\n",
        "limite_inferior = p25 - 1.5 * iqr\n",
        "limite_superior = p75 + 1.5 * iqr\n",
        "#dados do x para o x se o x for menor que o limite inferior ou se for maior que o limite superior\n",
        "outliers = [x for x in dados if x < limite_inferior or x > limite_superior]\n",
        "\n",
        "#variância (variance)\n",
        "variancia = np.var(dados)\n",
        "\n",
        "#desvio padrão amostral (standard deviation)\n",
        "#existe a população, onde pega apenas uma amostra e esse tipo de desvio vai ser somente da amostra\n",
        "#qts numeros precisa para ter uma qtd representativa na amostra\n",
        "desvio_padrao_amostral = np.std(dados, ddof=1) #precisa deifnir se ta trabalhando na amostra (ex:1) ou população (0)\n",
        "\n",
        "#ddof - grau de confiabilidade que deseja passar, o número pode variar\n",
        "\n",
        "#desvio padrão populacional (population standard deviation)\n",
        "desvio_padrao_populacional = np.std(dados, ddof=0)\n",
        "\n",
        "#amplitude (range)\n",
        "amplitude = np.max(dados) - np.min(dados)\n",
        "\n",
        "#estatísticas ordinais (moda)\n",
        "moda = stats.mode(dados, keepdims=True).mode[0] #nao aceita numero 0\n",
        "\n",
        "#percentil (exemplo: 90º percentil)\n",
        "percentil_90 = np.percentile(dados, 90)\n",
        "\n",
        "#quantil (exemplo: quantil 0.25 = Q1)\n",
        "quantil_25 = np.quantile(dados, 0.25)\n",
        "\n",
        "#desvio absoluto mediano da mediana (mad)\n",
        "mad = stats.median_absolute_deviation(dados)\n",
        "\n",
        "#valor esperado (ev) - esperança matemática\n",
        "valores = np.array([1, 2, 3,4, 5])\n",
        "probabilidades = np.array([0.1, 0.2, 0.3, 0.2, 0.2])\n",
        "valor_esperado = np.sum(valores * probabilidades)\n",
        "\n",
        "#exibindo valores\n"
      ]
    }
  ]
}